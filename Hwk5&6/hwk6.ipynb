{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the original binary MNIST data files in 0-255\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError( \"It needs to be between 'testing' and 'training'\")\n",
    "\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "        # print(len(lbl))\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromfile(fimg, dtype=np.uint8)      \n",
    "        image = image.reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_image = lambda idx: (lbl[idx], image[idx])\n",
    "\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_image(i)\n",
    "\n",
    "training_data = list(read(dataset = \"training\",path = r'C:\\Users\\Han\\Desktop\\Box Sync\\CS 559\\hwk2'))\n",
    "testing_data = list(read(dataset = \"testing\",path = r'C:\\Users\\Han\\Desktop\\Box Sync\\CS 559\\hwk2'))\n",
    "training_label = np.zeros((len(training_data),1))\n",
    "training_desiredout =np.zeros((len(training_data),10))\n",
    "training_image = np.zeros((len(training_data),28*28))\n",
    "testing_label = np.zeros((len(testing_data),1))\n",
    "testing_desiredout = np.zeros((len(testing_data),10))\n",
    "testing_image = np.zeros((len(testing_data),28*28))\n",
    "\n",
    "# split the training and testing data to labels and images\n",
    "for i in range(len(training_data)):\n",
    "    temp = training_data[i]\n",
    "    training_label[i] = temp[0]\n",
    "    training_desiredout[i,temp[0]] = 1 \n",
    "    training_image[i,] = temp[1].reshape(1,28*28)\n",
    "#training_label = training_label.reshape((1,60000))\n",
    "for i in range(len(testing_data)):\n",
    "    temp = testing_data[i]\n",
    "    testing_label[i] = temp[0]\n",
    "    testing_desiredout[i,temp[0]] = 1 \n",
    "    testing_image[i,] = temp[1].reshape(1,28*28)\n",
    "#testing_label = testing_label.reshape((1,10000))\n",
    "\n",
    "# Rename data\n",
    "X_train = training_image\n",
    "X_test = testing_image\n",
    "Y_train = training_desiredout\n",
    "Y_test = testing_desiredout\n",
    "# Standardize X (images from 0-255 to 0-1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## initialization\n",
    "np.random.seed(2)\n",
    "# use first n samples from training data to train the NN\n",
    "n = 60000\n",
    "# number of neurons in 1st hidden layer, N1\n",
    "N1 = 250\n",
    "# learning rate\n",
    "eta = 0.03\n",
    "# convergence threshold\n",
    "epsilon = 5e-8\n",
    "# epoch number \n",
    "epoch = 2\n",
    "# batch size\n",
    "bs = 1\n",
    "# initialize errors\n",
    "entropy = list()\n",
    "entropy.append(1e1)\n",
    "entropy.append(5e0)\n",
    "# initialize real outputs given the current w\n",
    "out = np.zeros((n,10))\n",
    "# initialize weights from input to 1st hidden layer\n",
    "u = np.random.uniform(-0.05,0.05,size = (784*N1)).reshape(784,N1)\n",
    "# initialize weights from 1st hidden layer to output\n",
    "v = np.random.uniform(-0.2,0.2,size = (10*N1)).reshape(N1,10)\n",
    "# initialzie the bias\n",
    "b = np.random.normal(-0.1,0.1,size = (bs*N1)).reshape(bs,N1)\n",
    "# initialize condi\n",
    "m = 0\n",
    "l = 0\n",
    "# intialize momentum\n",
    "momentum = 0.82\n",
    "\n",
    "# define softmax actiavtion function\n",
    "def softmax(w):\n",
    "    e = np.exp(np.array(w) - np.max(w))\n",
    "    dist = e / np.sum(e)\n",
    "    return dist\n",
    "# define a continuous vector to 0-1 vector functin\n",
    "def vec_to_01(x):\n",
    "    s1 = np.zeros(x.shape[0])\n",
    "    q = np.argmax(x)\n",
    "    s1[q] =1\n",
    "    return s1\n",
    "# define softmax's Jacobian matrix function\n",
    "def softmax_jacobian(s):\n",
    "    return np.diagflat(s) - np.outer(s, s)\n",
    "# define tanh's Jacobian matrix function\n",
    "def tanh_jacobian(t):\n",
    "    return np.diagflat(1-t**2)\n",
    "def cross_S(out, Label):\n",
    "    return - np.sum(np.multiply(out, np.log(Label)) + np.multiply((1-out), np.log(1-Label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current epoch is 2, entropy is 2.3293869, eta is 0.001.\n",
      "The current epoch is 4, entropy is 2.3156306, eta is 0.001.\n",
      "The current epoch is 6, entropy is 2.3145826, eta is 0.001.\n",
      "The current epoch is 8, entropy is 2.3144166, eta is 0.0005.\n",
      "The current epoch is 10, entropy is 2.3126246, eta is 0.0005.\n",
      "The current epoch is 12, entropy is 2.3125176, eta is 0.00025.\n",
      "The current epoch is 14, entropy is 2.3135191, eta is 0.00025.\n",
      "The current epoch is 16, entropy is 2.3121888, eta is 0.00025.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7266b2deb077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtemp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mtemp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtanh_jacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mgrad_u\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_rndm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mgrad_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_uold\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgrad_u\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mu\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mgrad_u\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Software\\Anaconda3_4.4.0\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mouter\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "while (np.abs(entropy[-1]-entropy[-2])>=epsilon):\n",
    "    m += 1\n",
    "    index = np.random.choice(np.arange(n), size= n,  replace=False)\n",
    "    X_train_rndm = X_train[index]\n",
    "    # re-initialzie last epoch's gradients\n",
    "    grad_uold = 0\n",
    "    grad_bold = 0\n",
    "    grad_vold = 0\n",
    "    # this loop is where we update the weights\n",
    "    for i in range(0,n, bs): \n",
    "        lf1 = np.dot(X_train_rndm[i:(i+bs)],u) + b  #compute the input layers' induced local field\n",
    "        z0 = np.tanh(lf1)          #compute the input layer's out\n",
    "        lf2 = np.dot(z0,v)             #compute the 1st H layers' induced local field\n",
    "        out[i:(i+bs)] = softmax(lf2)        #compute the 1st H layer's out\n",
    "        if (True):\n",
    "            # update u:   \n",
    "            temp1 = 2 / n * eta * np.sum(Y_train[i:(i+bs)] / out[i:(i+bs)], axis = 0).dot(softmax_jacobian(lf2))\n",
    "            temp2 = np.dot(temp1,v.T)\n",
    "            temp2 = temp2.dot(tanh_jacobian(lf1))\n",
    "            grad_u= np.outer(X_train_rndm[i:(i+bs)],temp2)\n",
    "            grad_u = grad_uold*momentum+grad_u\n",
    "            u -= grad_u\n",
    "            grad_uold = grad_u\n",
    "           \n",
    "            # update b:   \n",
    "            grad_b = (temp2)\n",
    "            grad_b = grad_bold*momentum+grad_b\n",
    "            b -=grad_b\n",
    "            grad_bold = grad_b\n",
    "           \n",
    "            # update v:  \n",
    "            grad_v = np.outer(z0, temp1)\n",
    "            grad_v = grad_vold*momentum+grad_v\n",
    "            v -=grad_v\n",
    "            grad_vold = grad_v\n",
    "            #if (i%1000 == 0):\n",
    "                 #print(np.mean(u**2),np.mean(b**2),np.mean(v**2),i)\n",
    "           \n",
    "            if np.isnan(v).sum ()>0:\n",
    "                break\n",
    "            \n",
    "    #  calculate mse for the current epoch\n",
    "    entropy.append(-np.sum(np.log(out) * Y_train)/n)\n",
    "    epoch +=1\n",
    "\n",
    "    if (epoch-2) % 2 == 0:\n",
    "        print('The current epoch is {}, entropy is {}, eta is {}.'.format((epoch-2) ,round(entropy[epoch-2],7) , eta))\n",
    "        if entropy[epoch-2] <= entropy[epoch-1]:\n",
    "            eta *= 0.5\n",
    "            \n",
    "            \n",
    "# delete the 2 dummpy points\n",
    "epoch -= 2\n",
    "del(entropy[0:2])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u0 = u\n",
    "b0 = b\n",
    "v0 = v\n",
    "#  Initialize errors = 0.\n",
    "error_test = 0\n",
    "# loop on all testing samples\n",
    "for i in range(10000):\n",
    "    lf1 = np.dot(X_train_rndm[i:(i+bs)],u) + b  #compute the input layers' induced local field\n",
    "    z0 = np.tanh(lf1)          #compute the input layer's out\n",
    "    lf2 = np.dot(z0,v)             #compute the 1st H layers' induced local field\n",
    "    out[i:(i+bs)] = softmax(lf2)        #compute the 1st H layer's out\n",
    "    # Find the largest component of v0 = [v0', v1', ...v9']^T^\n",
    "    predic_out = np.argmax(out[i,:])\n",
    "    #  If the prediceted output is different to the testing label, error +=1\n",
    "    diff = predic_out - np.argmax(Y_test[i,:])\n",
    "    if diff != 0:\n",
    "        error_test += 1\n",
    "error_test/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
